{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Home Personal documentation for all sort of thing, concept, tools, best practice, clean code, architecture, testing ...","title":"Home"},{"location":"#home","text":"Personal documentation for all sort of thing, concept, tools, best practice, clean code, architecture, testing ...","title":"Home"},{"location":"blue-green-deployment/","text":"Blue Green deployment Overview What is blue green deployment ? Blue Green deployment is a technique that reduces downtime and risk by running two identical production environments called Blue and Green. How it works ? At any time, only one of the environments is live, with the live environment serving all production traffic and the other environment being idle. We use a router to redirect all incoming traffic to the live environment. When we want to deploy new version of services we deploy only to the idle environment and after extensive testing we make the router switch environment. Now the environment that was idle is the live environment and has newest version of services. Advantages This technique can eliminate downtime due to app deployment. In addition, blue green deployment reduces risk: if something unexpected happens with your new version on Green, you can immediately roll back to the last version by switching back to Blue. Example As you prepare a new version of your software, deployment and the final stage of testing takes place in the environment that is not live: in this example, Green. Once you have deployed and fully tested the software in Green, you switch the router so all incoming requests now go to Green instead of Blue. Green is now live, and Blue is idle.","title":"Blue Green deployment"},{"location":"blue-green-deployment/#blue-green-deployment","text":"","title":"Blue Green deployment"},{"location":"blue-green-deployment/#overview","text":"","title":"Overview"},{"location":"blue-green-deployment/#what-is-blue-green-deployment","text":"Blue Green deployment is a technique that reduces downtime and risk by running two identical production environments called Blue and Green.","title":"What is blue green deployment ?"},{"location":"blue-green-deployment/#how-it-works","text":"At any time, only one of the environments is live, with the live environment serving all production traffic and the other environment being idle. We use a router to redirect all incoming traffic to the live environment. When we want to deploy new version of services we deploy only to the idle environment and after extensive testing we make the router switch environment. Now the environment that was idle is the live environment and has newest version of services.","title":"How it works ?"},{"location":"blue-green-deployment/#advantages","text":"This technique can eliminate downtime due to app deployment. In addition, blue green deployment reduces risk: if something unexpected happens with your new version on Green, you can immediately roll back to the last version by switching back to Blue.","title":"Advantages"},{"location":"blue-green-deployment/#example","text":"As you prepare a new version of your software, deployment and the final stage of testing takes place in the environment that is not live: in this example, Green. Once you have deployed and fully tested the software in Green, you switch the router so all incoming requests now go to Green instead of Blue. Green is now live, and Blue is idle.","title":"Example"},{"location":"docker/","text":"Docker What is docker ? Docker is an open platform for developing, shipping, and running applications. Docker enables you to separate your applications from your infrastructure so you can deliver software quickly. With Docker, you can manage your infrastructure in the same ways you manage your applications. By taking advantage of Docker\u2019s methodologies for shipping, testing, and deploying code quickly, you can significantly reduce the delay between writing code and running it in production. Advantages of docker Package and run an application in a loosely isolated environment called a container Containers are lightweight because they don\u2019t need the extra load of a hypervisor, but run directly within the host machine\u2019s kernel Isolation and security allow you to run many containers simultaneously on a given host Can run Docker containers within host machines that are actually virtual machines Easy and rapid app deployment to any cloud Scale app by multiplying the number of containers Usefull command Show all running containers docker ps Show all containers docker ps -a Show all images docker image ls Remove image docker image rm IMAGE_NAME Run a docker container from an image -d -> Dispatch, run in background -p -> Publish, map port 80 in the container to port 8080 on the docker host docker run -d -p 8080:80 IMAGE:TAG Build a docker image from a Dockerfile -t, Name and optionally a tag in the \u2018name:tag\u2019 format docker build -t NAME:TAG . Login to the interactive shell of a container docker exec -it <container_id_or_name> bash What is a Dockerfile ? Docker can build images automatically by reading the instructions from a Dockerfile. A Dockerfile is a text document that contains all the commands a user could call on the command line to assemble an image. Using docker build users can create an automated build that executes several command-line instructions in succession. Simple Java Dockerfile FROM openjdk:15 ARG JAR_FILE=target/*.jar COPY ${JAR_FILE} app.jar ENTRYPOINT [\"java\",\"-jar\",\"/app.jar\"] Docker Volume Volumes are the preferred mechanism for persisting data generated by and used by Docker containers. While bind mounts are dependent on the directory structure and OS of the host machine, volumes are completely managed by Docker. Volumes have several advantages over bind mounts: Volumes are easier to back up or migrate than bind mounts. You can manage volumes using Docker CLI commands or the Docker API. Volumes work on both Linux and Windows containers. Volumes can be more safely shared among multiple containers. Volume drivers let you store volumes on remote hosts or cloud providers, to encrypt the contents of volumes, or to add other functionality. New volumes can have their content pre-populated by a container. Volumes on Docker Desktop have much higher performance than bind mounts from Mac and Windows hosts. Volume usefull command Create volume docker volume create VOLUME_NAME Show all volume docker volume ls Delete volume docker volume rm VOLUME_NAME Inspect volume docker volume inspect VOLUME_NAME","title":"Docker"},{"location":"docker/#docker","text":"","title":"Docker"},{"location":"docker/#what-is-docker","text":"Docker is an open platform for developing, shipping, and running applications. Docker enables you to separate your applications from your infrastructure so you can deliver software quickly. With Docker, you can manage your infrastructure in the same ways you manage your applications. By taking advantage of Docker\u2019s methodologies for shipping, testing, and deploying code quickly, you can significantly reduce the delay between writing code and running it in production.","title":"What is docker ?"},{"location":"docker/#advantages-of-docker","text":"Package and run an application in a loosely isolated environment called a container Containers are lightweight because they don\u2019t need the extra load of a hypervisor, but run directly within the host machine\u2019s kernel Isolation and security allow you to run many containers simultaneously on a given host Can run Docker containers within host machines that are actually virtual machines Easy and rapid app deployment to any cloud Scale app by multiplying the number of containers","title":"Advantages of docker"},{"location":"docker/#usefull-command","text":"Show all running containers docker ps Show all containers docker ps -a Show all images docker image ls Remove image docker image rm IMAGE_NAME Run a docker container from an image -d -> Dispatch, run in background -p -> Publish, map port 80 in the container to port 8080 on the docker host docker run -d -p 8080:80 IMAGE:TAG Build a docker image from a Dockerfile -t, Name and optionally a tag in the \u2018name:tag\u2019 format docker build -t NAME:TAG . Login to the interactive shell of a container docker exec -it <container_id_or_name> bash","title":"Usefull command"},{"location":"docker/#what-is-a-dockerfile","text":"Docker can build images automatically by reading the instructions from a Dockerfile. A Dockerfile is a text document that contains all the commands a user could call on the command line to assemble an image. Using docker build users can create an automated build that executes several command-line instructions in succession.","title":"What is a Dockerfile ?"},{"location":"docker/#simple-java-dockerfile","text":"FROM openjdk:15 ARG JAR_FILE=target/*.jar COPY ${JAR_FILE} app.jar ENTRYPOINT [\"java\",\"-jar\",\"/app.jar\"]","title":"Simple Java Dockerfile"},{"location":"docker/#docker-volume","text":"Volumes are the preferred mechanism for persisting data generated by and used by Docker containers. While bind mounts are dependent on the directory structure and OS of the host machine, volumes are completely managed by Docker. Volumes have several advantages over bind mounts: Volumes are easier to back up or migrate than bind mounts. You can manage volumes using Docker CLI commands or the Docker API. Volumes work on both Linux and Windows containers. Volumes can be more safely shared among multiple containers. Volume drivers let you store volumes on remote hosts or cloud providers, to encrypt the contents of volumes, or to add other functionality. New volumes can have their content pre-populated by a container. Volumes on Docker Desktop have much higher performance than bind mounts from Mac and Windows hosts.","title":"Docker Volume"},{"location":"docker/#volume-usefull-command","text":"Create volume docker volume create VOLUME_NAME Show all volume docker volume ls Delete volume docker volume rm VOLUME_NAME Inspect volume docker volume inspect VOLUME_NAME","title":"Volume usefull command"},{"location":"how-to-add-documentation/","text":"How to add documentation Preview documentation You can preview the documentation on localhost by running the following command : mkdocs serve Local server will be available at Localhost and has hot reload. Build documentation After modifying the documentation you need to rebuild it by running the following command : mkdocs build Deploy documentation Once the documentation is build you need to deploy it on github page to do so we run the following command : mkdocs gh-deploy Documentation will be updated on github page and can be accessed at Link","title":"How to add documentation"},{"location":"how-to-add-documentation/#how-to-add-documentation","text":"","title":"How to add documentation"},{"location":"how-to-add-documentation/#preview-documentation","text":"You can preview the documentation on localhost by running the following command : mkdocs serve Local server will be available at Localhost and has hot reload.","title":"Preview documentation"},{"location":"how-to-add-documentation/#build-documentation","text":"After modifying the documentation you need to rebuild it by running the following command : mkdocs build","title":"Build documentation"},{"location":"how-to-add-documentation/#deploy-documentation","text":"Once the documentation is build you need to deploy it on github page to do so we run the following command : mkdocs gh-deploy Documentation will be updated on github page and can be accessed at Link","title":"Deploy documentation"},{"location":"mongodb/","text":"MongoDB MongoDB with docker -d, detach -p, publish port -v, specify volume for persistence docker run -d -p 27017:27017 --name MONGO_CONTAINER_NAME -v VOLUME_NAME:/data/db mongo:TAG If we specify credentials docker run -d -p 27017:27017 --name CONTAINER_NAME -v VOLUME_NAME:/data/db -e MONGO_INITDB_ROOT_USERNAME=USERNAME -e MONGO_INITDB_ROOT_PASSWORD=PASSWORD mongo:TAG We can interact with mongo directly from the container. First we need to interact with the container shell. docker exec -it MONGO_CONTAINER_NAME bash After we just need to type mongo in the interactive shell or mongo -u USERNAME -p PASSWORD if we have set credentials. MongoDB with spring Official documentation Basic property file : spring.data.mongodb.host=HOST spring.data.mongodb.port=PORT spring.data.mongodb.username=USERNAME spring.data.mongodb.password=PASSWORD spring.data.mongodb.authentication-database=admin spring.data.mongodb.database=DB_NAME Example of bean to init : @Bean public MongoClient mongoClient() { return MongoClients.create(\"mongodb://localhost:27017\"); } @Bean public MongoTemplate mongoTemplate(MongoClient mongoClient) { return new MongoTemplate(new SimpleMongoClientDatabaseFactory(mongoClient, \"testdb\")); }","title":"MongoDB"},{"location":"mongodb/#mongodb","text":"","title":"MongoDB"},{"location":"mongodb/#mongodb-with-docker","text":"-d, detach -p, publish port -v, specify volume for persistence docker run -d -p 27017:27017 --name MONGO_CONTAINER_NAME -v VOLUME_NAME:/data/db mongo:TAG If we specify credentials docker run -d -p 27017:27017 --name CONTAINER_NAME -v VOLUME_NAME:/data/db -e MONGO_INITDB_ROOT_USERNAME=USERNAME -e MONGO_INITDB_ROOT_PASSWORD=PASSWORD mongo:TAG We can interact with mongo directly from the container. First we need to interact with the container shell. docker exec -it MONGO_CONTAINER_NAME bash After we just need to type mongo in the interactive shell or mongo -u USERNAME -p PASSWORD if we have set credentials.","title":"MongoDB with docker"},{"location":"mongodb/#mongodb-with-spring","text":"Official documentation Basic property file : spring.data.mongodb.host=HOST spring.data.mongodb.port=PORT spring.data.mongodb.username=USERNAME spring.data.mongodb.password=PASSWORD spring.data.mongodb.authentication-database=admin spring.data.mongodb.database=DB_NAME Example of bean to init : @Bean public MongoClient mongoClient() { return MongoClients.create(\"mongodb://localhost:27017\"); } @Bean public MongoTemplate mongoTemplate(MongoClient mongoClient) { return new MongoTemplate(new SimpleMongoClientDatabaseFactory(mongoClient, \"testdb\")); }","title":"MongoDB with spring"},{"location":"mysql/","text":"MySQL MySQL with docker -d, detach -p, publish port -v, specify volume for persistence docker run --name CONTAINER_NAME -v VOLUME_NAME:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=PASSWORD -d -p 3306:3306 mysql:TAG We can interact with mysql directly from the container. First we need to interact with the container shell. docker exec -it CONTAINER_NAME bash After we just need to type mysql -pPASSWORD in the interactive shell.","title":"MySQL"},{"location":"mysql/#mysql","text":"","title":"MySQL"},{"location":"mysql/#mysql-with-docker","text":"-d, detach -p, publish port -v, specify volume for persistence docker run --name CONTAINER_NAME -v VOLUME_NAME:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=PASSWORD -d -p 3306:3306 mysql:TAG We can interact with mysql directly from the container. First we need to interact with the container shell. docker exec -it CONTAINER_NAME bash After we just need to type mysql -pPASSWORD in the interactive shell.","title":"MySQL with docker"},{"location":"swagger/","text":"Swagger Swagger with spring boot webflux <dependency> <groupId>io.springfox</groupId> <artifactId>springfox-boot-starter</artifactId> <version>3.0.0</version> </dependency> http://host:port/swagger-ui/index.html","title":"Swagger"},{"location":"swagger/#swagger","text":"","title":"Swagger"},{"location":"swagger/#swagger-with-spring-boot-webflux","text":"<dependency> <groupId>io.springfox</groupId> <artifactId>springfox-boot-starter</artifactId> <version>3.0.0</version> </dependency> http://host:port/swagger-ui/index.html","title":"Swagger with spring boot webflux"},{"location":"workflow/continuous-integration/","text":"Continuous Integration Private git at start Git machine user, collaborator of project Machine user have ssh key associated Dockerize at start with logging in mind Fluent bit Multiple process docker : startup.sh script Elasticsearch Jenkins Jobs at start Build Job Release Job Push Job Jenkins env variable AWS Region Tools : Maven/Java Jenkins credentials AWS Access/Secret RabbitMQ secret etc... Problem ? docker.sock permission > Go root and chmod 777 docker.sock Git permission > Go /var/lib/jenkins/.ssh/. Add \"config\" file with git host pointing to ssh key of git machine user (See Deploy key git documentation ) Need to use jenkins user ? Go root sudo -s Then change to jenkins user su - jenkins -s /bin/bash","title":"Continuous Integration"},{"location":"workflow/continuous-integration/#continuous-integration","text":"","title":"Continuous Integration"},{"location":"workflow/continuous-integration/#private-git-at-start","text":"Git machine user, collaborator of project Machine user have ssh key associated","title":"Private git at start"},{"location":"workflow/continuous-integration/#dockerize-at-start-with-logging-in-mind","text":"Fluent bit Multiple process docker : startup.sh script Elasticsearch","title":"Dockerize at start with logging in mind"},{"location":"workflow/continuous-integration/#jenkins-jobs-at-start","text":"Build Job Release Job Push Job","title":"Jenkins Jobs at start"},{"location":"workflow/continuous-integration/#jenkins-env-variable","text":"AWS Region Tools : Maven/Java","title":"Jenkins env variable"},{"location":"workflow/continuous-integration/#jenkins-credentials","text":"AWS Access/Secret RabbitMQ secret etc...","title":"Jenkins credentials"},{"location":"workflow/continuous-integration/#problem","text":"docker.sock permission > Go root and chmod 777 docker.sock Git permission > Go /var/lib/jenkins/.ssh/. Add \"config\" file with git host pointing to ssh key of git machine user (See Deploy key git documentation ) Need to use jenkins user ? Go root sudo -s Then change to jenkins user su - jenkins -s /bin/bash","title":"Problem ?"},{"location":"workflow/deployment/","text":"Deployment Aws IAM User IAM Role Cognito VPC Subnet Security Group Routing table Internet gateway ECS Task definition Create deployment at start of project","title":"Deployment"},{"location":"workflow/deployment/#deployment","text":"","title":"Deployment"},{"location":"workflow/deployment/#aws","text":"IAM User IAM Role Cognito VPC Subnet Security Group Routing table Internet gateway ECS Task definition","title":"Aws"},{"location":"workflow/deployment/#create-deployment-at-start-of-project","text":"","title":"Create deployment at start of project"},{"location":"workflow/development/","text":"Development Clean architecture Clients layer Core Layer/ Application layer/ Domain layer/ Infrastructure layer Configuration layer Folder structure production code clients/ configuration/ core/ . application/ . domain/ infrastructure/ Folder structure test unit/ integration/ e2e/ tools/ BDD/TDD -> Use case testing Wishful thinking programming Test from use case (Outside-in diamond tpierrain) (application layer) Few fine-grained test from domain Stub every infrastructure code Make test code that can be easily refactor. Anti Fragile Test Only test behaviour Best ref = Tpierrain Video DDD Entity ValueObject Repository Factory Domain Event Model code to speak the same language as the domain Relationship need to be clear Env variable in properties file random.variable=${RANDOM_VARIABLE} Unit testing strategy A lot of test from use case Few test from domain for complex part or hard to test from use case part Refactoring in mind Only test behaviour Stub every infrastructure code Integration testing strategy Test ONLY ADAPTER, one at a time (clients/infrastructure) Use TestContainer Use wire mock Use webflux test (Mock service) If we use managed service, fake it with TestContainer and make a lot of test with it Few test with real distant managed service, only important path E2E testing strategy We want to see that all part work together with the real configuration but with local endpoint. Services come from TestContainer TestContainer WireMock (Or cloud stub contract) No load balancer No remote config TestContainer Setup one time launch easily every time Distributed Logging Fluent-bit Elasticsearch","title":"Development"},{"location":"workflow/development/#development","text":"","title":"Development"},{"location":"workflow/development/#clean-architecture","text":"Clients layer Core Layer/ Application layer/ Domain layer/ Infrastructure layer Configuration layer","title":"Clean architecture"},{"location":"workflow/development/#folder-structure-production-code","text":"clients/ configuration/ core/ . application/ . domain/ infrastructure/","title":"Folder structure production code"},{"location":"workflow/development/#folder-structure-test","text":"unit/ integration/ e2e/ tools/","title":"Folder structure test"},{"location":"workflow/development/#bddtdd-use-case-testing","text":"Wishful thinking programming Test from use case (Outside-in diamond tpierrain) (application layer) Few fine-grained test from domain Stub every infrastructure code Make test code that can be easily refactor. Anti Fragile Test Only test behaviour Best ref = Tpierrain Video","title":"BDD/TDD -&gt; Use case testing"},{"location":"workflow/development/#ddd","text":"Entity ValueObject Repository Factory Domain Event Model code to speak the same language as the domain Relationship need to be clear","title":"DDD"},{"location":"workflow/development/#env-variable-in-properties-file","text":"random.variable=${RANDOM_VARIABLE}","title":"Env variable in properties file"},{"location":"workflow/development/#unit-testing-strategy","text":"A lot of test from use case Few test from domain for complex part or hard to test from use case part Refactoring in mind Only test behaviour Stub every infrastructure code","title":"Unit testing strategy"},{"location":"workflow/development/#integration-testing-strategy","text":"Test ONLY ADAPTER, one at a time (clients/infrastructure) Use TestContainer Use wire mock Use webflux test (Mock service) If we use managed service, fake it with TestContainer and make a lot of test with it Few test with real distant managed service, only important path","title":"Integration testing strategy"},{"location":"workflow/development/#e2e-testing-strategy","text":"We want to see that all part work together with the real configuration but with local endpoint. Services come from TestContainer TestContainer WireMock (Or cloud stub contract) No load balancer No remote config","title":"E2E testing strategy"},{"location":"workflow/development/#testcontainer","text":"Setup one time launch easily every time","title":"TestContainer"},{"location":"workflow/development/#distributed-logging","text":"Fluent-bit Elasticsearch","title":"Distributed Logging"},{"location":"workflow/plan/","text":"Plan Plan a maximum of use case Practice example mapping Same as cucumber spec Practice event storming Discover implication of every action","title":"Plan"},{"location":"workflow/plan/#plan","text":"","title":"Plan"},{"location":"workflow/plan/#plan-a-maximum-of-use-case","text":"","title":"Plan a maximum of use case"},{"location":"workflow/plan/#practice-example-mapping","text":"Same as cucumber spec","title":"Practice example mapping"},{"location":"workflow/plan/#practice-event-storming","text":"Discover implication of every action","title":"Practice event storming"}]}