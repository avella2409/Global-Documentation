{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Home Personal documentation for all sort of thing, concept, tools, best practice, clean code, architecture, testing ...","title":"Home"},{"location":"#home","text":"Personal documentation for all sort of thing, concept, tools, best practice, clean code, architecture, testing ...","title":"Home"},{"location":"blue-green-deployment/","text":"Blue Green deployment Overview What is blue green deployment ? Blue Green deployment is a technique that reduces downtime and risk by running two identical production environments called Blue and Green. How it works ? At any time, only one of the environments is live, with the live environment serving all production traffic and the other environment being idle. We use a router to redirect all incoming traffic to the live environment. When we want to deploy new version of services we deploy only to the idle environment and after extensive testing we make the router switch environment. Now the environment that was idle is the live environment and has newest version of services. Advantages This technique can eliminate downtime due to app deployment. In addition, blue green deployment reduces risk: if something unexpected happens with your new version on Green, you can immediately roll back to the last version by switching back to Blue. Example As you prepare a new version of your software, deployment and the final stage of testing takes place in the environment that is not live: in this example, Green. Once you have deployed and fully tested the software in Green, you switch the router so all incoming requests now go to Green instead of Blue. Green is now live, and Blue is idle.","title":"Blue Green deployment"},{"location":"blue-green-deployment/#blue-green-deployment","text":"","title":"Blue Green deployment"},{"location":"blue-green-deployment/#overview","text":"","title":"Overview"},{"location":"blue-green-deployment/#what-is-blue-green-deployment","text":"Blue Green deployment is a technique that reduces downtime and risk by running two identical production environments called Blue and Green.","title":"What is blue green deployment ?"},{"location":"blue-green-deployment/#how-it-works","text":"At any time, only one of the environments is live, with the live environment serving all production traffic and the other environment being idle. We use a router to redirect all incoming traffic to the live environment. When we want to deploy new version of services we deploy only to the idle environment and after extensive testing we make the router switch environment. Now the environment that was idle is the live environment and has newest version of services.","title":"How it works ?"},{"location":"blue-green-deployment/#advantages","text":"This technique can eliminate downtime due to app deployment. In addition, blue green deployment reduces risk: if something unexpected happens with your new version on Green, you can immediately roll back to the last version by switching back to Blue.","title":"Advantages"},{"location":"blue-green-deployment/#example","text":"As you prepare a new version of your software, deployment and the final stage of testing takes place in the environment that is not live: in this example, Green. Once you have deployed and fully tested the software in Green, you switch the router so all incoming requests now go to Green instead of Blue. Green is now live, and Blue is idle.","title":"Example"},{"location":"docker/","text":"Docker What is docker ? Docker is an open platform for developing, shipping, and running applications. Docker enables you to separate your applications from your infrastructure so you can deliver software quickly. With Docker, you can manage your infrastructure in the same ways you manage your applications. By taking advantage of Docker\u2019s methodologies for shipping, testing, and deploying code quickly, you can significantly reduce the delay between writing code and running it in production. Advantages of docker Package and run an application in a loosely isolated environment called a container Containers are lightweight because they don\u2019t need the extra load of a hypervisor, but run directly within the host machine\u2019s kernel Isolation and security allow you to run many containers simultaneously on a given host Can run Docker containers within host machines that are actually virtual machines Easy and rapid app deployment to any cloud Scale app by multiplying the number of containers Usefull command Show all running containers docker ps Show all containers docker ps -a Show all images docker image ls Remove image docker image rm IMAGE_NAME Run a docker container from an image -d -> Dispatch, run in background -p -> Publish, map port 80 in the container to port 8080 on the docker host docker run -d -p 8080:80 IMAGE:TAG Build a docker image from a Dockerfile -t, Name and optionally a tag in the \u2018name:tag\u2019 format docker build -t NAME:TAG . Login to the interactive shell of a container docker exec -it <container_id_or_name> bash What is a Dockerfile ? Docker can build images automatically by reading the instructions from a Dockerfile. A Dockerfile is a text document that contains all the commands a user could call on the command line to assemble an image. Using docker build users can create an automated build that executes several command-line instructions in succession. Simple Java Dockerfile FROM openjdk:15 ARG JAR_FILE=target/*.jar COPY ${JAR_FILE} app.jar ENTRYPOINT [\"java\",\"-jar\",\"/app.jar\"] Docker Volume Volumes are the preferred mechanism for persisting data generated by and used by Docker containers. While bind mounts are dependent on the directory structure and OS of the host machine, volumes are completely managed by Docker. Volumes have several advantages over bind mounts: Volumes are easier to back up or migrate than bind mounts. You can manage volumes using Docker CLI commands or the Docker API. Volumes work on both Linux and Windows containers. Volumes can be more safely shared among multiple containers. Volume drivers let you store volumes on remote hosts or cloud providers, to encrypt the contents of volumes, or to add other functionality. New volumes can have their content pre-populated by a container. Volumes on Docker Desktop have much higher performance than bind mounts from Mac and Windows hosts. Volume usefull command Create volume docker volume create VOLUME_NAME Show all volume docker volume ls Delete volume docker volume rm VOLUME_NAME Inspect volume docker volume inspect VOLUME_NAME","title":"Docker"},{"location":"docker/#docker","text":"","title":"Docker"},{"location":"docker/#what-is-docker","text":"Docker is an open platform for developing, shipping, and running applications. Docker enables you to separate your applications from your infrastructure so you can deliver software quickly. With Docker, you can manage your infrastructure in the same ways you manage your applications. By taking advantage of Docker\u2019s methodologies for shipping, testing, and deploying code quickly, you can significantly reduce the delay between writing code and running it in production.","title":"What is docker ?"},{"location":"docker/#advantages-of-docker","text":"Package and run an application in a loosely isolated environment called a container Containers are lightweight because they don\u2019t need the extra load of a hypervisor, but run directly within the host machine\u2019s kernel Isolation and security allow you to run many containers simultaneously on a given host Can run Docker containers within host machines that are actually virtual machines Easy and rapid app deployment to any cloud Scale app by multiplying the number of containers","title":"Advantages of docker"},{"location":"docker/#usefull-command","text":"Show all running containers docker ps Show all containers docker ps -a Show all images docker image ls Remove image docker image rm IMAGE_NAME Run a docker container from an image -d -> Dispatch, run in background -p -> Publish, map port 80 in the container to port 8080 on the docker host docker run -d -p 8080:80 IMAGE:TAG Build a docker image from a Dockerfile -t, Name and optionally a tag in the \u2018name:tag\u2019 format docker build -t NAME:TAG . Login to the interactive shell of a container docker exec -it <container_id_or_name> bash","title":"Usefull command"},{"location":"docker/#what-is-a-dockerfile","text":"Docker can build images automatically by reading the instructions from a Dockerfile. A Dockerfile is a text document that contains all the commands a user could call on the command line to assemble an image. Using docker build users can create an automated build that executes several command-line instructions in succession.","title":"What is a Dockerfile ?"},{"location":"docker/#simple-java-dockerfile","text":"FROM openjdk:15 ARG JAR_FILE=target/*.jar COPY ${JAR_FILE} app.jar ENTRYPOINT [\"java\",\"-jar\",\"/app.jar\"]","title":"Simple Java Dockerfile"},{"location":"docker/#docker-volume","text":"Volumes are the preferred mechanism for persisting data generated by and used by Docker containers. While bind mounts are dependent on the directory structure and OS of the host machine, volumes are completely managed by Docker. Volumes have several advantages over bind mounts: Volumes are easier to back up or migrate than bind mounts. You can manage volumes using Docker CLI commands or the Docker API. Volumes work on both Linux and Windows containers. Volumes can be more safely shared among multiple containers. Volume drivers let you store volumes on remote hosts or cloud providers, to encrypt the contents of volumes, or to add other functionality. New volumes can have their content pre-populated by a container. Volumes on Docker Desktop have much higher performance than bind mounts from Mac and Windows hosts.","title":"Docker Volume"},{"location":"docker/#volume-usefull-command","text":"Create volume docker volume create VOLUME_NAME Show all volume docker volume ls Delete volume docker volume rm VOLUME_NAME Inspect volume docker volume inspect VOLUME_NAME","title":"Volume usefull command"},{"location":"how-to-add-documentation/","text":"How to add documentation Preview documentation You can preview the documentation on localhost by running the following command : mkdocs serve Local server will be available at Localhost and has hot reload. Build documentation After modifying the documentation you need to rebuild it by running the following command : mkdocs build Deploy documentation Once the documentation is build you need to deploy it on github page to do so we run the following command : mkdocs gh-deploy Documentation will be updated on github page and can be accessed at Link","title":"How to add documentation"},{"location":"how-to-add-documentation/#how-to-add-documentation","text":"","title":"How to add documentation"},{"location":"how-to-add-documentation/#preview-documentation","text":"You can preview the documentation on localhost by running the following command : mkdocs serve Local server will be available at Localhost and has hot reload.","title":"Preview documentation"},{"location":"how-to-add-documentation/#build-documentation","text":"After modifying the documentation you need to rebuild it by running the following command : mkdocs build","title":"Build documentation"},{"location":"how-to-add-documentation/#deploy-documentation","text":"Once the documentation is build you need to deploy it on github page to do so we run the following command : mkdocs gh-deploy Documentation will be updated on github page and can be accessed at Link","title":"Deploy documentation"},{"location":"mongodb/","text":"MongoDB MongoDB with docker -d, detach -p, publish port -v, specify volume for persistence docker run -d -p 27017:27017 --name MONGO_CONTAINER_NAME -v VOLUME_NAME:/data/db mongo:TAG If we specify credentials docker run -d -p 27017:27017 --name CONTAINER_NAME -v VOLUME_NAME:/data/db -e MONGO_INITDB_ROOT_USERNAME=USERNAME -e MONGO_INITDB_ROOT_PASSWORD=PASSWORD mongo:TAG We can interact with mongo directly from the container. First we need to interact with the container shell. docker exec -it MONGO_CONTAINER_NAME bash After we just need to type mongo in the interactive shell or mongo -u USERNAME -p PASSWORD if we have set credentials. MongoDB with spring Official documentation Basic property file : spring.data.mongodb.host=HOST spring.data.mongodb.port=PORT spring.data.mongodb.username=USERNAME spring.data.mongodb.password=PASSWORD spring.data.mongodb.authentication-database=admin spring.data.mongodb.database=DB_NAME Example of bean to init : @Bean public MongoClient mongoClient() { return MongoClients.create(\"mongodb://localhost:27017\"); } @Bean public MongoTemplate mongoTemplate(MongoClient mongoClient) { return new MongoTemplate(new SimpleMongoClientDatabaseFactory(mongoClient, \"testdb\")); }","title":"MongoDB Container"},{"location":"mongodb/#mongodb","text":"","title":"MongoDB"},{"location":"mongodb/#mongodb-with-docker","text":"-d, detach -p, publish port -v, specify volume for persistence docker run -d -p 27017:27017 --name MONGO_CONTAINER_NAME -v VOLUME_NAME:/data/db mongo:TAG If we specify credentials docker run -d -p 27017:27017 --name CONTAINER_NAME -v VOLUME_NAME:/data/db -e MONGO_INITDB_ROOT_USERNAME=USERNAME -e MONGO_INITDB_ROOT_PASSWORD=PASSWORD mongo:TAG We can interact with mongo directly from the container. First we need to interact with the container shell. docker exec -it MONGO_CONTAINER_NAME bash After we just need to type mongo in the interactive shell or mongo -u USERNAME -p PASSWORD if we have set credentials.","title":"MongoDB with docker"},{"location":"mongodb/#mongodb-with-spring","text":"Official documentation Basic property file : spring.data.mongodb.host=HOST spring.data.mongodb.port=PORT spring.data.mongodb.username=USERNAME spring.data.mongodb.password=PASSWORD spring.data.mongodb.authentication-database=admin spring.data.mongodb.database=DB_NAME Example of bean to init : @Bean public MongoClient mongoClient() { return MongoClients.create(\"mongodb://localhost:27017\"); } @Bean public MongoTemplate mongoTemplate(MongoClient mongoClient) { return new MongoTemplate(new SimpleMongoClientDatabaseFactory(mongoClient, \"testdb\")); }","title":"MongoDB with spring"},{"location":"mysql/","text":"MySQL MySQL with docker -d, detach -p, publish port -v, specify volume for persistence docker run --name CONTAINER_NAME -v VOLUME_NAME:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=PASSWORD -d -p 3306:3306 mysql:TAG We can interact with mysql directly from the container. First we need to interact with the container shell. docker exec -it CONTAINER_NAME bash After we just need to type mysql -pPASSWORD in the interactive shell.","title":"MySQL Container"},{"location":"mysql/#mysql","text":"","title":"MySQL"},{"location":"mysql/#mysql-with-docker","text":"-d, detach -p, publish port -v, specify volume for persistence docker run --name CONTAINER_NAME -v VOLUME_NAME:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=PASSWORD -d -p 3306:3306 mysql:TAG We can interact with mysql directly from the container. First we need to interact with the container shell. docker exec -it CONTAINER_NAME bash After we just need to type mysql -pPASSWORD in the interactive shell.","title":"MySQL with docker"},{"location":"swagger/","text":"Swagger Swagger with spring boot webflux <dependency> <groupId>io.springfox</groupId> <artifactId>springfox-boot-starter</artifactId> <version>3.0.0</version> </dependency> http://host:port/swagger-ui/index.html","title":"Swagger"},{"location":"swagger/#swagger","text":"","title":"Swagger"},{"location":"swagger/#swagger-with-spring-boot-webflux","text":"<dependency> <groupId>io.springfox</groupId> <artifactId>springfox-boot-starter</artifactId> <version>3.0.0</version> </dependency> http://host:port/swagger-ui/index.html","title":"Swagger with spring boot webflux"},{"location":"production/production-ready/","text":"Production Ready Workflow Goal Overview of the process to make production ready application. Steps Be prepared Plan a maximum of use case What the application need to achieve ? Identify read process Identify write process Practice example mapping (Like cucumber spec) Practice event storming. Discover implication of every action Make App deployable from start Create git repository Add git machine user as collaborator of the new repository Dockerize app with distributed logging in mind Create Jenkins jobs. BUILD/RELEASE/PUSH to ECR Create AWS deployment process Deploy app with the full pipeline from commit to deploy Make App flexible Clean architecture / Hexagonal architecture / Port and adapter Create a core with an application layer and a domain layer Application layer contains all use cases of the application A use case interact with the domain layer Domain layer contains all domain related logic Create an infrastructure layer. Infrastructure layer implement all interface of the domain layer. Create a client layer. Client layer call the application layer. Make App safe and easy to refactor Use test driven development Wishful thinking programming. Model the code the way we wish it was already implemented. Act like all complex functionality are already implemented. Create unit test (From the use case) Create integration test Create e2e test Folder structure production code clients/ configuration/ core/ . application/ . domain/ infrastructure/ Folder structure test unit/ integration/ e2e/ tools/ Unit testing strategy Create a lot of test for use cases ( Outside-in diamond ) Create test for the domain when it's hard to test it from the use case Create builder with domain specific syntax to build the use case. Make it easily composable. Make test easy to refactor Only test behavior Stub every infrastructure code. Create stub that implement interface of the domain layer. Unit test communicate only with the core of the application Integration testing strategy Test only adapter, one at a time (clients/infrastructure) Use TestContainer Use WireMock Use WebFluxTest. Mock use case. If we use managed service and there is a docker container doing the same use TestContainer and create a lot of test. Create only few test with the real distant managed service, test most important path. E2E testing strategy We want to check all the part of the application work together with the real configuration Use TestContainer not real distant service (Already tested in integration test) Use WireMock (Or cloud stub contract) No load balancer No remote config Distributed Logging Fluent-bit agent. Push log from file to remote server. Elasticsearch. Easy to visualize data with kibana and es. We could also use a log4j2 appender that send log to remote server. Service discovery / Load balancing Netflix eureka Remote Config Spring cloud config Api Gateway Spring cloud gateway Api Documentation Swagger Monitoring Prometheus","title":"Production Ready"},{"location":"production/production-ready/#production-ready-workflow","text":"","title":"Production Ready Workflow"},{"location":"production/production-ready/#goal","text":"Overview of the process to make production ready application.","title":"Goal"},{"location":"production/production-ready/#steps","text":"","title":"Steps"},{"location":"production/production-ready/#be-prepared","text":"Plan a maximum of use case What the application need to achieve ? Identify read process Identify write process Practice example mapping (Like cucumber spec) Practice event storming. Discover implication of every action","title":"Be prepared"},{"location":"production/production-ready/#make-app-deployable-from-start","text":"Create git repository Add git machine user as collaborator of the new repository Dockerize app with distributed logging in mind Create Jenkins jobs. BUILD/RELEASE/PUSH to ECR Create AWS deployment process Deploy app with the full pipeline from commit to deploy","title":"Make App deployable from start"},{"location":"production/production-ready/#make-app-flexible","text":"Clean architecture / Hexagonal architecture / Port and adapter Create a core with an application layer and a domain layer Application layer contains all use cases of the application A use case interact with the domain layer Domain layer contains all domain related logic Create an infrastructure layer. Infrastructure layer implement all interface of the domain layer. Create a client layer. Client layer call the application layer.","title":"Make App flexible"},{"location":"production/production-ready/#make-app-safe-and-easy-to-refactor","text":"Use test driven development Wishful thinking programming. Model the code the way we wish it was already implemented. Act like all complex functionality are already implemented. Create unit test (From the use case) Create integration test Create e2e test","title":"Make App safe and easy to refactor"},{"location":"production/production-ready/#folder-structure-production-code","text":"clients/ configuration/ core/ . application/ . domain/ infrastructure/","title":"Folder structure production code"},{"location":"production/production-ready/#folder-structure-test","text":"unit/ integration/ e2e/ tools/","title":"Folder structure test"},{"location":"production/production-ready/#unit-testing-strategy","text":"Create a lot of test for use cases ( Outside-in diamond ) Create test for the domain when it's hard to test it from the use case Create builder with domain specific syntax to build the use case. Make it easily composable. Make test easy to refactor Only test behavior Stub every infrastructure code. Create stub that implement interface of the domain layer. Unit test communicate only with the core of the application","title":"Unit testing strategy"},{"location":"production/production-ready/#integration-testing-strategy","text":"Test only adapter, one at a time (clients/infrastructure) Use TestContainer Use WireMock Use WebFluxTest. Mock use case. If we use managed service and there is a docker container doing the same use TestContainer and create a lot of test. Create only few test with the real distant managed service, test most important path.","title":"Integration testing strategy"},{"location":"production/production-ready/#e2e-testing-strategy","text":"We want to check all the part of the application work together with the real configuration Use TestContainer not real distant service (Already tested in integration test) Use WireMock (Or cloud stub contract) No load balancer No remote config","title":"E2E testing strategy"},{"location":"production/production-ready/#distributed-logging","text":"Fluent-bit agent. Push log from file to remote server. Elasticsearch. Easy to visualize data with kibana and es. We could also use a log4j2 appender that send log to remote server.","title":"Distributed Logging"},{"location":"production/production-ready/#service-discovery-load-balancing","text":"Netflix eureka","title":"Service discovery / Load balancing"},{"location":"production/production-ready/#remote-config","text":"Spring cloud config","title":"Remote Config"},{"location":"production/production-ready/#api-gateway","text":"Spring cloud gateway","title":"Api Gateway"},{"location":"production/production-ready/#api-documentation","text":"Swagger","title":"Api Documentation"},{"location":"production/production-ready/#monitoring","text":"Prometheus","title":"Monitoring"}]}